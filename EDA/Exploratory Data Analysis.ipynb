{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e25ea09-74d6-47e6-bad6-e922f52c3532",
   "metadata": {},
   "source": [
    "# Personal Information\n",
    "Name: **Anh Tran**\n",
    "\n",
    "StudentID: **12770698**\n",
    "\n",
    "Email: [**anh.tran1@student.uva.nl**](anh.tran1@student.uva.nl)\n",
    "\n",
    "Submitted on: **DD.MM.YYYY**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cf6243-adfe-4eb8-bba3-bb2835079abd",
   "metadata": {},
   "source": [
    "# Data Context\n",
    "**In this section you should introduce the datasources and datasets which you will be working with. Explain where they are from as well as their domain. Give an overview of what the context of the data is. You should not spend more than 1 to 2 paragraphs here as the core information will be in the next section.**\n",
    "\n",
    "The topic of this research project is to explore gentrification - the process of a neighborhood changing as a result of wealthier residents moving in, bringing investments and physical improvements, but displacing existing residents as prices rise and cultures homogenized or replaced. This project examines the visual indicators of gentrification, more specifically in the signage of storefronts in Amsterdam, by applying computer vision methods on images of facades in the city.\n",
    "\n",
    "The image dataset used in this project is from the [StreetSwipe project](http://streetswipe.aestheticsofexclusion.com/about.php). Via crowd-sourcing, the project let people decide which facade is gentrified, by voting \"Yes\" or \"No\" on the streetview images. The official *gentrified* and *non-gentrified* labels are generated based the majority of votes for each facade. Additionally, if subsequent voters decides against the majority, they are prompted to provide a textual explanation for their vote.\n",
    "\n",
    "On this data, scene-text detection will be applied to identify the region of the images that contain storefront signage. With the text region extracted (still as an image), font recognition and color extraction will be done to understand these attributes; and text recognition will be applied to extract machine-readable text strings, whose semantic meanings will be studied using word embedding. This pipeline will be applied on gentrified and non-gentrified labelled subsets of the data, and ultimately the learnt attributes (fonts, colors, semantics) of these classes are compared to understand what is seen as gentrified."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a833d964-56e1-49c7-8172-7435357624aa",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "\n",
    "**Present here the results of your exploratory data analysis. Note that there is no need to have a \"story line\" - it is more important that you show your understanding of the data and the methods that you will be using in your experiments (i.e. your methodology).**\n",
    "\n",
    "**As an example, you could show data, label, or group balances, skewness, and basic characterizations of the data. Information about data frequency and distributions as well as results from reduction mechanisms such as PCA could be useful. Furthermore, indicate outliers and how/why you are taking them out of your samples, if you do so.**\n",
    "\n",
    "**The idea is, that you conduct this analysis to a) understand the data better but b) also to verify the shapes of the distributions and whether they meet the assumptions of the methods that you will attempt to use. Finally, make good use of images, diagrams, and tables to showcase what information you have extracted from your data.**\n",
    "\n",
    "As you can see, you are in a jupyter notebook environment here. This means that you should focus little on writing text and more on actually exploring your data. If you need to, you can use the amsmath environment in-line: $e=mc^2$ or also in separate equations such as here:\n",
    "\n",
    "\\begin{equation}\n",
    "    e=mc^2 \\mathrm{\\space where \\space} e,m,c\\in \\mathbb{R}\n",
    "\\end{equation}\n",
    "\n",
    "Furthermore, you can insert images such as your data aggregation diagrams like this:\n",
    "\n",
    "<!-- ![image](example.png) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "534317db-d881-4e33-a358-754e2881e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "# from bq_helper import BigQueryHelper\n",
    "from dask import bag, diagnostics \n",
    "from urllib import request\n",
    "import cv2\n",
    "import missingno as msno\n",
    "import hvplot.pandas  # custom install\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582b299-f599-4140-a454-bcbfdeeb273f",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0cf9be-2cac-4227-957f-ad893212e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2b796dc-f69d-4686-b802-bd0d8f679ee8",
   "metadata": {},
   "source": [
    "### Label csv\n",
    "Pre-processing (rename columns etc)\n",
    "* Note difference in number of response in pre- and post- versions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4df9546-a6d7-4678-aca6-cd13d5f3c79a",
   "metadata": {},
   "source": [
    "### Images: \n",
    "Make sure to add some explanation of what you are doing in your code. This will help you and whoever will read this a lot in following your steps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7e0ef85",
   "metadata": {},
   "source": [
    "#### Sample size per class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fd40e81",
   "metadata": {},
   "source": [
    "#### Specs\n",
    "* Size\n",
    "* Dimensions\n",
    "* Aspect ratios (width/height)\n",
    "* Avg width and height\n",
    "* Resolution\n",
    "* Colors\n",
    "\n",
    "In relation to models' img size requirements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94de70ee",
   "metadata": {},
   "source": [
    "#### Visual analysis\n",
    "Noted that there are plenty of instances where non-gentrified facades contain no signage - something that can be directly concluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a889a6c7-aed8-4a0f-9925-c4f8e2fce1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also don't forget to comment your code\n",
    "# This way it's also easier to spot thought errors along the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c33b453f-1bc2-4cad-8021-e548d307f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a93498a17b64b82d2668b9ba9847f5a31ece7b6c3d2a4939f417333be8a7c83b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
