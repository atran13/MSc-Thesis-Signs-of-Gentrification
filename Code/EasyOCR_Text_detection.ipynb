{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atran13/MSc-Thesis-Signs-of-Gentrification/blob/main/Code/EasyOCR_Text_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrzEA4JLajAK",
        "outputId": "873501a4-3d74-4f13-8e3a-16b8b752b23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIHB4oLCYZc1"
      },
      "outputs": [],
      "source": [
        "# !pip install easyocr\n",
        "import os,sys,shutil\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "# import easyocr\n",
        "# from paddleocr import PaddleOCR, draw_ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vjFMt1gYZc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e306f874-0c75-47d5-dce3-fe88ef27c72d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        }
      ],
      "source": [
        "# Specify language to identify from images\n",
        "reader = easyocr.Reader(['en','nl'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThbnYuqWYZc2"
      },
      "source": [
        "## Detect & crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ-TEHRIYZc3"
      },
      "outputs": [],
      "source": [
        "def extract_text(origin, destination):\n",
        "    \"\"\"\n",
        "    :origin: Folder containing images\n",
        "    :destination: Folder to contain cropped-out text instances\n",
        "    \"\"\"\n",
        "    no_text = 0\n",
        "    num_file = 0\n",
        "    instances = 0\n",
        "    for file in glob.glob(os.path.join(origin,'*.jpg')):\n",
        "        num_file += 1\n",
        "        filename = os.path.split(file)[1] # {name}.jpg\n",
        "        dir = os.path.join(destination, filename)\n",
        "\n",
        "        # Read img\n",
        "        img = cv2.imread(file)\n",
        "\n",
        "        # Detect texts\n",
        "        result = reader.detect(img, add_margin=0)\n",
        "\n",
        "        # Crop & save text regions\n",
        "        if not any([result[0][0], result[1][0]]): # if no text detected\n",
        "            no_text += 1\n",
        "        else:\n",
        "            os.makedirs(dir) # make folder for image with text\n",
        "\n",
        "            for i, box in enumerate(result[0][0]):\n",
        "                instances += 1\n",
        "                tl = (max(0,box[0]), max(0,box[2]))\n",
        "                br = (max(0,box[1]), max(0,box[3]))\n",
        "                cropped_rec = img[tl[1]:br[1], tl[0]:br[0]]\n",
        "\n",
        "                des_path = os.path.join(dir, f'rec-{i}.jpg')\n",
        "                if cropped_rec is not None:\n",
        "                    cv2.imwrite(des_path, cropped_rec)\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "            for i, box in enumerate(result[1][0]):\n",
        "                instances += 1\n",
        "                rect = cv2.minAreaRect(np.array(box, dtype=np.int32))\n",
        "\n",
        "                width = int(rect[1][0])\n",
        "                height = int(rect[1][1])\n",
        "\n",
        "                bound = cv2.boxPoints(rect) ; bound = np.int0(bound)\n",
        "\n",
        "                src_pts = bound.astype(\"float32\")\n",
        "\n",
        "                if width > height:\n",
        "                    dst_pts = np.array([[0, height-1],\n",
        "                                        [0, 0],\n",
        "                                        [width-1, 0],\n",
        "                                        [width-1, height-1]],\n",
        "                                        dtype=\"float32\")\n",
        "                    perspective_matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "                    cropped_poly = cv2.warpPerspective(img, perspective_matrix, (width, height))\n",
        "                else:\n",
        "                    dst_pts = np.array([[0, 0],\n",
        "                                        [height-1, 0],\n",
        "                                        [height-1, width-1],\n",
        "                                        [0, width-1]],\n",
        "                                        dtype=\"float32\")\n",
        "\n",
        "                    perspective_matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "                    cropped_poly = cv2.warpPerspective(img, perspective_matrix, (height, width))\n",
        "\n",
        "                des_path = os.path.join(dir, f'poly-{i}.jpg')\n",
        "                if cropped_poly is not None:\n",
        "                    cv2.imwrite(des_path, cropped_poly)\n",
        "                else:\n",
        "                    pass\n",
        "    print(f\"Number of text instances: {instances}\")\n",
        "    print(f\"Number of images without text: {no_text} ({(100 * no_text/num_file):.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kn3cRDZfkHg"
      },
      "outputs": [],
      "source": [
        "# modified for panoramic data, to keep tree structure\n",
        "def extract_text_p(origin, destination):\n",
        "    \"\"\"\n",
        "    :origin: Folder containing images, grouped by gentrified/non-gentrified\n",
        "    :destination: Folder to contain cropped-out text instances, grouped by gentrified/non-gentrified\n",
        "    \"\"\"\n",
        "    no_text = 0\n",
        "    num_file = 0\n",
        "    instances = 0\n",
        "    record = os.path.join(destination, \"img-with-text.txt\")\n",
        "    open(record, 'a').close()\n",
        "\n",
        "    # neighborhood per class (gentrified/non-gentrified)\n",
        "    nbhd_dir = glob.glob(os.path.join(origin,\"*\")) # AmsPano/images_classified/{(non)gentrified}/{* = nbhd}\n",
        "    for nbhd_folder in nbhd_dir:\n",
        "        nbhd_name = os.path.split(nbhd_folder)[1]\n",
        "        des_nbhd_folder = os.path.join(destination, nbhd_name) # AmsPano/images_cropped/{(non)gentrified}/{nbhd}\n",
        "        os.makedirs(des_nbhd_folder) # Make corresponding folder for nbhd in new directory\n",
        "\n",
        "        # location per nbhd (lon-lat)\n",
        "        location_dir = glob.glob(os.path.join(nbhd_folder, \"*\"))\n",
        "        for location in location_dir:\n",
        "            location_name = os.path.split(location)[1]\n",
        "            des_location_folder = os.path.join(des_nbhd_folder, location_name) # AmsPano/images_cropped/{(non)gentrified}/{* = nbhd}\n",
        "\n",
        "            # img per location\n",
        "            img_dir = glob.glob(os.path.join(location, \"*.jpg\"))\n",
        "            for image in img_dir:\n",
        "                num_file += 1\n",
        "                img_name = os.path.split(image)[1]\n",
        "\n",
        "                # Read img\n",
        "                img = cv2.imread(image)\n",
        "                # Detect texts\n",
        "                result = reader.detect(img, add_margin=0)\n",
        "\n",
        "                # Crop & save text regions\n",
        "                if not any([result[0][0], result[1][0]]): # If no text detected\n",
        "                    no_text += 1\n",
        "                else: # If text detected\n",
        "                    with open(str(record), \"a\") as f:\n",
        "                        f.write(img_name + '\\n') # Record img name\n",
        "                    if not os.path.exists(des_location_folder):\n",
        "                        os.makedirs(des_location_folder) # Make corresponding folder for img location in new directory\n",
        "\n",
        "                    for i, box in enumerate(result[0][0]):\n",
        "                        instances += 1\n",
        "                        tl = (max(0,box[0]), max(0,box[2]))\n",
        "                        br = (max(0,box[1]), max(0,box[3]))\n",
        "                        cropped_rec = img[tl[1]:br[1], tl[0]:br[0]]\n",
        "\n",
        "                        des_path = os.path.join(des_location_folder, f'rec-{i}.jpg')\n",
        "                        if cropped_rec is not None:\n",
        "                            cv2.imwrite(des_path, cropped_rec)\n",
        "                        else:\n",
        "                            pass\n",
        "\n",
        "                    for i, box in enumerate(result[1][0]):\n",
        "                        instances += 1\n",
        "                        rect = cv2.minAreaRect(np.array(box, dtype=np.int32))\n",
        "\n",
        "                        width = int(rect[1][0])\n",
        "                        height = int(rect[1][1])\n",
        "\n",
        "                        bound = cv2.boxPoints(rect) ; bound = np.int0(bound)\n",
        "\n",
        "                        src_pts = bound.astype(\"float32\")\n",
        "\n",
        "                        if width > height:\n",
        "                            dst_pts = np.array([[0, height-1],\n",
        "                                                [0, 0],\n",
        "                                                [width-1, 0],\n",
        "                                                [width-1, height-1]],\n",
        "                                                dtype=\"float32\")\n",
        "                            perspective_matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "                            cropped_poly = cv2.warpPerspective(img, perspective_matrix, (width, height))\n",
        "                        else:\n",
        "                            dst_pts = np.array([[0, 0],\n",
        "                                                [height-1, 0],\n",
        "                                                [height-1, width-1],\n",
        "                                                [0, width-1]],\n",
        "                                                dtype=\"float32\")\n",
        "\n",
        "                            perspective_matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "                            cropped_poly = cv2.warpPerspective(img, perspective_matrix, (height, width))\n",
        "\n",
        "                        des_path = os.path.join(des_location_folder, f'poly-{i}.jpg')\n",
        "                        if cropped_poly is not None:\n",
        "                            cv2.imwrite(des_path, cropped_poly)\n",
        "                        else:\n",
        "                            pass\n",
        "    print(f\"Number of text instances: {instances}\")\n",
        "    print(f\"Number of images without text: {no_text} ({(100 * no_text/num_file):.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARJkyHgnrgVt"
      },
      "outputs": [],
      "source": [
        "# modified for panoramic data LEFT & RIGHT views, keeping tree structure\n",
        "def extract_text_lr(origin, destination):\n",
        "    \"\"\"\n",
        "    :origin: Folder containing images, grouped by gentrified/non-gentrified\n",
        "    :destination: Folder to contain cropped-out text instances, grouped by gentrified/non-gentrified\n",
        "    \"\"\"\n",
        "    no_text = 0\n",
        "    num_file = 0\n",
        "    instances = 0\n",
        "    record = os.path.join(destination, \"lr-img-with-text.txt\")\n",
        "    open(record, 'a').close()\n",
        "\n",
        "    # neighborhood per class (gentrified/non-gentrified)\n",
        "    nbhd_dir = glob.glob(os.path.join(origin,\"*\")) # AmsPano/images_classified/{(non)gentrified}/{* = nbhd}\n",
        "    for nbhd_folder in nbhd_dir:\n",
        "        nbhd_name = os.path.split(nbhd_folder)[1]\n",
        "        des_nbhd_folder = os.path.join(destination, nbhd_name) # AmsPano/images_cropped/{(non)gentrified}/{nbhd}\n",
        "        os.makedirs(des_nbhd_folder) # Make corresponding folder for nbhd in new directory\n",
        "\n",
        "        # location per nbhd (lon-lat)\n",
        "        location_dir = glob.glob(os.path.join(nbhd_folder, \"*\"))\n",
        "        for location in location_dir:\n",
        "            location_name = os.path.split(location)[1]\n",
        "            des_location_folder = os.path.join(des_nbhd_folder, location_name) # AmsPano/images_cropped/{(non)gentrified}/{* = nbhd}\n",
        "\n",
        "            # img in subfolder per location\n",
        "            img_dir = glob.glob(os.path.join(location, \"*/*.jpg\"))\n",
        "            for image in img_dir:\n",
        "                img_name = os.path.split(image)[1]\n",
        "                if img_name == \"_left.jpg\" or img_name == \"_right.jpg\":\n",
        "                    num_file += 1\n",
        "                    # Read img\n",
        "                    img = cv2.imread(image)\n",
        "                    # Detect texts\n",
        "                    result = reader.detect(img, add_margin=0)\n",
        "\n",
        "                    # Crop & save text regions\n",
        "                    if not any([result[0][0], result[1][0]]): # If no text detected\n",
        "                        no_text += 1\n",
        "                    else: # If text detected\n",
        "                        with open(str(record), \"a\") as f:\n",
        "                            f.write(location_name + '\\n') # Record img name\n",
        "                        if not os.path.exists(des_location_folder):\n",
        "                            os.makedirs(des_location_folder) # Make corresponding folder for img location in new directory\n",
        "\n",
        "                        for i, box in enumerate(result[0][0]):\n",
        "                            instances += 1\n",
        "                            tl = (max(0,box[0]), max(0,box[2]))\n",
        "                            br = (max(0,box[1]), max(0,box[3]))\n",
        "                            cropped_rec = img[tl[1]:br[1], tl[0]:br[0]]\n",
        "\n",
        "                            des_path = os.path.join(des_location_folder, f'rec-{i}.jpg')\n",
        "                            if cropped_rec is not None:\n",
        "                                cv2.imwrite(des_path, cropped_rec)\n",
        "\n",
        "                        for i, box in enumerate(result[1][0]):\n",
        "                            instances += 1\n",
        "                            rect = cv2.minAreaRect(np.array(box, dtype=np.int32))\n",
        "\n",
        "                            width = int(rect[1][0])\n",
        "                            height = int(rect[1][1])\n",
        "\n",
        "                            bound = cv2.boxPoints(rect) ; bound = np.int0(bound)\n",
        "\n",
        "                            src_pts = bound.astype(\"float32\")\n",
        "\n",
        "                            if width > height:\n",
        "                                dst_pts = np.array([[0, height-1],\n",
        "                                                    [0, 0],\n",
        "                                                    [width-1, 0],\n",
        "                                                    [width-1, height-1]],\n",
        "                                                    dtype=\"float32\")\n",
        "                                perspective_matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "                                cropped_poly = cv2.warpPerspective(img, perspective_matrix, (width, height))\n",
        "                            else:\n",
        "                                dst_pts = np.array([[0, 0],\n",
        "                                                    [height-1, 0],\n",
        "                                                    [height-1, width-1],\n",
        "                                                    [0, width-1]],\n",
        "                                                    dtype=\"float32\")\n",
        "\n",
        "                                perspective_matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "                                cropped_poly = cv2.warpPerspective(img, perspective_matrix, (height, width))\n",
        "\n",
        "                            des_path = os.path.join(des_location_folder, f'poly-{i}.jpg')\n",
        "                            if cropped_poly is not None:\n",
        "                                cv2.imwrite(des_path, cropped_poly)\n",
        "\n",
        "    print(f\"Number of text instances: {instances}\")\n",
        "    print(f\"Number of images without text: {no_text} ({(100 * no_text/num_file):.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UGS0bzAMZIn"
      },
      "outputs": [],
      "source": [
        "# modified for panoramic data queried w/ OSM, keeping tree structure\n",
        "def extract_text_osm(origin, destination):\n",
        "    \"\"\"\n",
        "    :origin: Folder containing images, grouped by gentrified/non-gentrified\n",
        "    :destination: Folder to contain cropped-out text instances, grouped by gentrified/non-gentrified\n",
        "    \"\"\"\n",
        "    no_text = 0\n",
        "    num_file = 0\n",
        "    instances = 0\n",
        "    record = os.path.join(destination, \"osm-img-with-text.txt\")\n",
        "    open(record, 'a').close()\n",
        "\n",
        "    # location per nbhd (lon-lat)\n",
        "    location_dir = glob.glob(os.path.join(origin, \"*\"))\n",
        "    for location in location_dir:\n",
        "        location_name = os.path.split(location)[1]\n",
        "        des_location_folder = os.path.join(destination, location_name) # AmsPano/images_cropped/{(non)gentrified}/{* = nbhd}\n",
        "\n",
        "        # img in subfolder per location\n",
        "        img_dir = glob.glob(os.path.join(location, \"*.jpg\"))\n",
        "        for image in img_dir:\n",
        "            img_name = os.path.split(image)[1]\n",
        "            num_file += 1\n",
        "            # Read img\n",
        "            img = cv2.imread(image)\n",
        "            # Detect texts\n",
        "            result = reader.detect(img, add_margin=0)\n",
        "\n",
        "            # Crop & save text regions\n",
        "            if not any([result[0][0], result[1][0]]): # If no text detected\n",
        "                no_text += 1\n",
        "            else: # If text detected\n",
        "                with open(str(record), \"a\") as f:\n",
        "                    f.write(location_name + '/' + image_name + '\\n') # Record img\n",
        "                if not os.path.exists(des_location_folder):\n",
        "                    os.makedirs(des_location_folder) # Make corresponding folder for img location in new directory\n",
        "\n",
        "                for i, box in enumerate(result[0][0]):\n",
        "                    instances += 1\n",
        "                    tl = (max(0,box[0]), max(0,box[2]))\n",
        "                    br = (max(0,box[1]), max(0,box[3]))\n",
        "                    cropped_rec = img[tl[1]:br[1], tl[0]:br[0]]\n",
        "\n",
        "                    des_path = os.path.join(des_location_folder, f'rec-{i}.jpg')\n",
        "                    if cropped_rec is not None:\n",
        "                        cv2.imwrite(des_path, cropped_rec)\n",
        "\n",
        "                for i, box in enumerate(result[1][0]):\n",
        "                    instances += 1\n",
        "                    rect = cv2.minAreaRect(np.array(box, dtype=np.int32))\n",
        "\n",
        "                    width = int(rect[1][0])\n",
        "                    height = int(rect[1][1])\n",
        "\n",
        "                    bound = cv2.boxPoints(rect) ; bound = np.int0(bound)\n",
        "\n",
        "                    src_pts = bound.astype(\"float32\")\n",
        "\n",
        "                    if width > height:\n",
        "                        dst_pts = np.array([[0, height-1],\n",
        "                                            [0, 0],\n",
        "                                            [width-1, 0],\n",
        "                                            [width-1, height-1]],\n",
        "                                            dtype=\"float32\")\n",
        "                        perspective_matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "                        cropped_poly = cv2.warpPerspective(img, perspective_matrix, (width, height))\n",
        "                    else:\n",
        "                        dst_pts = np.array([[0, 0],\n",
        "                                            [height-1, 0],\n",
        "                                            [height-1, width-1],\n",
        "                                            [0, width-1]],\n",
        "                                            dtype=\"float32\")\n",
        "\n",
        "                        perspective_matrix = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "                        cropped_poly = cv2.warpPerspective(img, perspective_matrix, (height, width))\n",
        "\n",
        "                    des_path = os.path.join(des_location_folder, f'poly-{i}.jpg')\n",
        "                    if cropped_poly is not None:\n",
        "                        cv2.imwrite(des_path, cropped_poly)\n",
        "\n",
        "    print(f\"Number of text instances: {instances}\")\n",
        "    print(f\"Number of images without text: {no_text} ({(100 * no_text/num_file):.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# StreetSwipe"
      ],
      "metadata": {
        "id": "Aydrw-5xKKVB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCqRQeJQYZc3"
      },
      "outputs": [],
      "source": [
        "# make folders for cropped-out texts\n",
        "# class_names = ['gentrified','non-gentrified']\n",
        "# new_folder = '/content/drive/MyDrive/MASTERS/Thesis/Data/StreetSwipe/images_cropped'\n",
        "# for name in class_names:\n",
        "#     os.makedirs(os.path.join(new_folder, name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "origin_gen = '/content/drive/MyDrive/MASTERS/Thesis/Data/StreetSwipe/images_classified/gentrified/'\n",
        "origin_nongen = '/content/drive/MyDrive/MASTERS/Thesis/Data/StreetSwipe/images_classified/non-gentrified/'"
      ],
      "metadata": {
        "id": "qtaEkC7uxTu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gentrified"
      ],
      "metadata": {
        "id": "4VQQ003UVWo3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71cXks4dYZc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "630b16ce-156a-4014-df04-dffef0813fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text instances: 2819\n",
            "Number of images without text: 24 (3.38%)\n"
          ]
        }
      ],
      "source": [
        "destination_gen = '/content/drive/MyDrive/MASTERS/Thesis/Data/StreetSwipe/images_cropped/gentrified/'\n",
        "# extract_text(origin_gen, destination_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-604lNVeYZc4"
      },
      "source": [
        "### Non-gentrified"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "destination_nongen = '/content/drive/MyDrive/MASTERS/Thesis/Data/StreetSwipe/images_cropped/non-gentrified/'\n",
        "# extract_text(origin_nongen, destination_nongen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRZ2uUX0WJp1",
        "outputId": "c9c5e589-9c4b-4994-9701-d6af83a2c6a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text instances: 7680\n",
            "Number of images without text: 109 (6.30%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Panoramic left&right"
      ],
      "metadata": {
        "id": "u2vEYYbPRiYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make folders for cropped-out texts\n",
        "# class_names = ['gentrified','non-gentrified']\n",
        "# new_folder = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_cropped_lr'\n",
        "# for name in class_names:\n",
        "#     os.makedirs(os.path.join(new_folder, name))"
      ],
      "metadata": {
        "id": "ZXBleAxPRoVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gentrified"
      ],
      "metadata": {
        "id": "-EuP5aN6R_Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "origin_gen_lr = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_classified/gentrified/'\n",
        "destination_gen_lr = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_cropped_lr/gentrified/'\n",
        "# extract_text_lr(origin_gen_lr, destination_gen_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vlFYBFfSCow",
        "outputId": "4855d1b6-8287-48ad-ad60-ad29ee3a8e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text instances: 1738\n",
            "Number of images without text: 3658 (80.04%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-gentrified"
      ],
      "metadata": {
        "id": "PP7h1b-eSarY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "origin_nongen_lr = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_classified/non-gentrified/'\n",
        "destination_nongen_lr = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_cropped_lr/non-gentrified/'\n",
        "# extract_text_lr(origin_nongen_lr, destination_nongen_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m503lPNSdeA",
        "outputId": "05681ccb-b1de-44d2-8e48-c8d470abb739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text instances: 1139\n",
            "Number of images without text: 3720 (85.40%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OSM"
      ],
      "metadata": {
        "id": "sldLXrKLbyZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make folders for cropped-out texts\n",
        "# class_names = ['gentrified','non-gentrified']\n",
        "# new_folder = '/content/drive/MyDrive/MASTERS/Thesis/Data/OSM/osm_1/cropped/'\n",
        "# for name in class_names:\n",
        "#     os.makedirs(os.path.join(new_folder, name))"
      ],
      "metadata": {
        "id": "ek3Uqm_Bb3HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gentrified"
      ],
      "metadata": {
        "id": "LD60zwFZk0Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "origin_gen_osm = '/content/drive/MyDrive/MASTERS/Thesis/Data/OSM/osm_1/classified/gentrified/' # 402\n",
        "destination_gen_osm = '/content/drive/MyDrive/MASTERS/Thesis/Data/OSM/osm_1/cropped/gentrified/'\n",
        "extract_text_osm(origin_gen_osm, destination_gen_osm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZA218WIk3Iw",
        "outputId": "4e7ccc1a-0308-4bd9-ad02-5b28143f47fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text instances: 477\n",
            "Number of images without text: 550 (68.41%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-gentrified"
      ],
      "metadata": {
        "id": "gllb1ccclZuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "origin_nongen_osm = '/content/drive/MyDrive/MASTERS/Thesis/Data/OSM/osm_1/classified/non-gentrified/' # 96\n",
        "destination_nongen_osm = '/content/drive/MyDrive/MASTERS/Thesis/Data/OSM/osm_1/cropped/non-gentrified/'\n",
        "extract_text_osm(origin_nongen_osm, destination_nongen_osm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCHpgcnBlsat",
        "outputId": "35f7a4e5-8d73-46ec-b912-829a356685a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text instances: 241\n",
            "Number of images without text: 98 (51.04%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Panoramas"
      ],
      "metadata": {
        "id": "5lWOcjKsU7m4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make folders for cropped-out texts\n",
        "# class_names = ['gentrified','non-gentrified']\n",
        "# new_folder = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_cropped'\n",
        "# for name in class_names:\n",
        "#     os.makedirs(os.path.join(new_folder, name))"
      ],
      "metadata": {
        "id": "ElFDcOddVdUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gentrified"
      ],
      "metadata": {
        "id": "0YFeG3AoVbvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "origin_gen_p = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_classified/gentrified/'\n",
        "destination_gen_p = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_cropped/gentrified/'\n",
        "# extract_text_p(origin_gen_p, destination_gen_p)"
      ],
      "metadata": {
        "id": "Lp9YxsNqU9v6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f59ddb-2df1-46e4-cccc-d4bc2d867725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text instances: 5132\n",
            "Number of images without text: 831 (36.37%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-gentrified"
      ],
      "metadata": {
        "id": "s6GG1ekNVKfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "origin_nongen_p = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_classified/non-gentrified/'\n",
        "destination_nongen_p = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_cropped/non-gentrified/'\n",
        "# extract_text_p(origin_nongen_p, destination_nongen_p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P3MjQlCVMQu",
        "outputId": "4d94e443-e71e-47fe-f90f-c64275a9e085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text instances: 3386\n",
            "Number of images without text: 814 (48.66%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Panoramic left&right&front"
      ],
      "metadata": {
        "id": "1p2E_PWZvc57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make folders for cropped-out texts\n",
        "# class_names = ['gentrified','non-gentrified']\n",
        "# new_folder = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_cropped_lrf'\n",
        "# for name in class_names:\n",
        "#     os.makedirs(os.path.join(new_folder, name))"
      ],
      "metadata": {
        "id": "O1baU-uLvc6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gentrified"
      ],
      "metadata": {
        "id": "lQbvvspLvc6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "origin_gen_lrf = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_classified/gentrified/'\n",
        "destination_gen_lrf = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_cropped_lrf/gentrified/'\n",
        "# extract_text_lrf(origin_gen_lrf, destination_gen_lrf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e5b718-5cf2-43d9-f379-2238d29f447d",
        "id": "hDYdlW4Wvc6G"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text instances: 2113\n",
            "Number of images without text: 5691 (83.02%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-gentrified"
      ],
      "metadata": {
        "id": "jGFOZuK_vc6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "origin_nongen_lrf = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_classified/non-gentrified/'\n",
        "destination_nongen_lrf = '/content/drive/MyDrive/MASTERS/Thesis/Data/AmsPano/images_cropped_lrf/non-gentrified/'\n",
        "# extract_text_lrf(origin_nongen_lrf, destination_nongen_lrf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa13b5c3-2b33-46ed-bbbf-8d936ffa4bfc",
        "id": "lvhS7ff3vc6G"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of text instances: 1418\n",
            "Number of images without text: 5707 (87.34%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a93498a17b64b82d2668b9ba9847f5a31ece7b6c3d2a4939f417333be8a7c83b"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Aydrw-5xKKVB",
        "u2vEYYbPRiYd",
        "5lWOcjKsU7m4",
        "1p2E_PWZvc57"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}